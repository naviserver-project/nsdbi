
* TODO


** A standard scheme for common database errors such as 'duplicate row' when
   inserting a new row with a primary key which is already taken. Turn these
   into exceptions so that Tcl code can catch them.

   Maybe just bubble up 6 char SQL error code and hope all dbs do something
   sane.  Need to checlk.


** Result caching: Caching the results from a db query is easy, but flushing
   is complicated. You often want to flush a whole class of cached results
   because they depend upon the values in some other table which was just
   updated. Perhaps results can be cached with multiple keys:

     # All 'it' results flushed atomically.
     dbi_dml -cachekey it$id -cachekey it {update ... :id ...}

     # Return cached result for key it$id if available.
     dbi_rows -cachekey it$id {select ... :id ...}

     # Flush every 'it'.
     dbi_flush -cachekey it

   Suspect the right thing to do here is add multi-key support to standard
   cache commands as it has wide applicability. Probably also better to
   


** Limits for pools?  Set max handles, default pool etc. per urlspecific
   data. So: dbi commands run from pages under /foo/bar would by default get a
   handle from pool x if none specified.  If there are 6 concurrent pages
   running under /foo/bar and there are 10 handles in pool x but the limit
   says 6, the next page will have to wait.

   The goal is to abstract pool names from Tcl code.  Pool names can change --
   they should be in a config file.  e.g. a site grows large and partitions
   user data into two databases: usernames a-m -> pool1, usernames n-z pool2
   etc.

   Like ns_limits.


** Add Url2Pool callbacks (See url2file) to determine which handle to use
   when?  e.g. round-robin requests between 3 databases?


** Add higher level Tcl commands 'update', 'insert' etc.

     set a(x) 1; set a(y) 2; set a(z) 3

     dbi_update tablex $a

     # Translates to:

     dbi_dml -bindarray a -- {
         update tablex set x = :x, y = :y, z = :z
     }

     # And:

     dbi_insert tablex $a

     # Translates to:

     dbi_dml -bindarray a -- {
         insert into tablex
         (x, y, z)
         values
         (:x, :y, :z)
     }

     # MySQL has this native. Others could wrap in a transaction:
     # If row exists, update. Otherwise, insert (atomically).

     dbi_insertorupdate tablex $a


** Predefined schema queries for drivers. i.e. you want to know which tables
   are defined, or how many columns a table has.  Drivers supply a string of
   SQL which returns the correct answer. Can override in config file for weird
   db setups.

     foreach table [dbi_tables pool1] {
         dbi_columns $table
     }

   Probably not going to do this. Just query the SQL standard
   information_schema, or simulate it with views.


** Array operations (Oracle array DML etc.) with native driver support?

     # 3 inserts in single transaction, efficiently:
     dbi_dml {insert into tablex (x) values (:x)} a b c


** Asynchronous API. Send a query to the db, initiate an HTTP request to some
   outside service, submit an ns_job: *concurrently*.  Wait for all the
   results to come back.

   This could be extended so that multiple db queries are submitted from
   within the driver thread.  A conn thread would only be allocated when
   notification that all query results are ready. This would prevent conn
   threads sitting idle waiting for db I/O.

   The hard part is coming up with an API which is actually workable.

   Problems: postgres supports asynchronous queries but mysql and sqlite do
   not. Could write own implementation of mysql protocol. Could simulate
   with threads. Could have optional support for asynch dbs.
